{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# {TITLE}\n",
    "\n",
    "- **Author:** {AUTHOR} \n",
    "- **Email:** {EMAIL}\n",
    "- **Date:** {DATE}\n",
    "\n",
    "{DESCRIPTION}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips\n",
    "\n",
    "1.\n",
    "    If the distribution is highly concentrated, with most samples falling within a narrow range, \n",
    "    which indicates an uneven spread of the data.\n",
    "\n",
    "    When generating a subset of the dataset, only a small number of samples with higher values \n",
    "    are included, resulting in a skewed distribution and causing outliers in the test set.\n",
    "    Outliers are data points that differ significantly from other observations and can distort \n",
    "    statistical analyses, leading to a high Mean Squared Error (MSE) when their values are far \n",
    "    from the training set's maximum values.\n",
    "\n",
    "    To address this issue, try normalizing the data before splitting the dataset into training \n",
    "    and testing subsets. Normalizing beforehand can help ensure a more balanced distribution, \n",
    "    reducing the impact of outliers.\n",
    "\n",
    "    Ideally, creating a larger dataset with more diverse samples and then applying proper \n",
    "    preprocessing would help achieve a more representative distribution, minimizing outliers \n",
    "    and improving overall model performance.\n",
    "\n",
    "2.\n",
    "    Debug every variable and data before using it for training. Make sure they are correctly implemented.\n",
    "    \n",
    "    Otherwise, the model will not work properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "from keras import layers, Input, Model\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Disable TensorFlow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. GPU Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.13.0\n",
      "Running on CPU (No CUDA support detected)\n",
      "No GPUs found\n",
      "Running on CPU\n",
      "Error enabling memory growth: No GPUs found\n"
     ]
    }
   ],
   "source": [
    "def get_gpu_info():\n",
    "    \"\"\"\n",
    "    Retrieves and prints detailed GPU information including TensorFlow,\n",
    "    CUDA, cuDNN versions, number of GPUs, and memory details.\n",
    "    \"\"\"\n",
    "    # Display TensorFlow version\n",
    "    print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "\n",
    "    # Check if TensorFlow is built with CUDA support and retrieve build info\n",
    "    if tf.test.is_built_with_cuda():\n",
    "        build_info = tf.sysconfig.get_build_info()\n",
    "        print(f\"TensorFlow is built with CUDA support\")\n",
    "        print(f\"CUDA Version: {build_info['cuda_version']}\")\n",
    "        print(f\"cuDNN Version: {build_info['cudnn_version']}\")\n",
    "    else:\n",
    "        print(\"Running on CPU (No CUDA support detected)\")\n",
    "\n",
    "    # Detect available GPUs\n",
    "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "    if gpus:\n",
    "        print(f\"Number of GPUs detected: {len(gpus)}\")\n",
    "        print(f\"Available GPU(s): {[gpu.name for gpu in gpus]}\")\n",
    "        for i, gpu in enumerate(gpus):\n",
    "            # Get GPU details using logical device configuration\n",
    "            details = tf.config.experimental.get_device_details(gpu)\n",
    "\n",
    "            memory_info = tf.config.experimental.get_memory_info(gpu.name)\n",
    "            print(f\"GPU {i} Details:\")\n",
    "            print(f\"  Name: {details.get('device_name', 'Unknown')}\")\n",
    "            print(f\"  Total Memory: {memory_info.get('total', 'Unknown')} bytes\")\n",
    "            print(f\"  Free Memory: {memory_info.get('free', 'Unknown')} bytes\")\n",
    "\n",
    "        print(f\"Using GPU: {tf.test.gpu_device_name()}\")\n",
    "    else:\n",
    "        print(\"No GPUs found\")\n",
    "        print(\"Running on CPU\")\n",
    "get_gpu_info()\n",
    "\n",
    "def enable_memory_growth():\n",
    "    \"\"\"\n",
    "    Enables memory growth for all detected GPUs.\n",
    "    \"\"\"\n",
    "    # Specify GPU to use (e.g., GPU 0)\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "    if gpus:\n",
    "        for i, gpu in enumerate(gpus):\n",
    "            try:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "                print(f\"Memory growth enabled for GPU {i}: {gpu.name}\")\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error enabling memory growth for GPU {i}: {gpu.name}, {e}\")\n",
    "    else:\n",
    "        print(\"Error enabling memory growth: No GPUs found\")\n",
    "enable_memory_growth()\n",
    "\n",
    "# Specify GPU to use (e.g., GPU 0)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Constants and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "TOTAL_NUM_PORTS = 144  # Total number of ports\n",
    "BATCH_SIZE = 32  # Batch size for training\n",
    "EPOCHS = 20  # Number of epochs for training\n",
    "\n",
    "# Threshold in dB for outage probability\n",
    "OUTAGE_THRESHOLD = 20  \n",
    "\n",
    "# Scaling Method\n",
    "SCALER = MinMaxScaler(clip=True)\n",
    "\n",
    "# Checkpoint and Log Directories\n",
    "CHECKPOINT_DIR = \"dnn_checkpoints\"\n",
    "if not os.path.exists(CHECKPOINT_DIR):\n",
    "    os.makedirs(CHECKPOINT_DIR)\n",
    "    \n",
    "LOG_DIR = os.path.join(\"dnn_logs\", \"fit\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sinr_data(filepath, key=\"gamma_k\"):\n",
    "    \"\"\"\n",
    "    Loads SINR data from a .mat file.\n",
    "\n",
    "    The function reads a .mat file and extracts a specified key that contains the SINR matrix data. \n",
    "    This is useful for importing and accessing SINR values stored in MATLAB files.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to the .mat file containing the SINR data.\n",
    "        key (str, optional): Key used to extract the SINR matrix from the loaded .mat file. \n",
    "                             Defaults to \"gamma_k\".\n",
    "\n",
    "    Returns:\n",
    "        sinr_matrix (numpy.ndarray): A 2D array containing the SINR values extracted from the .mat file.\n",
    "    \"\"\"\n",
    "    # Load the .mat file\n",
    "    mat = scipy.io.loadmat(filepath)\n",
    "\n",
    "    # Extract the SINR matrix\n",
    "    sinr_matrix = mat[key]\n",
    "\n",
    "    return sinr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "sinr_data = load_sinr_data('data/Rayleigh/SNR_ports.mat')\n",
    "sinr_data = sinr_data[:int(1.0 * sinr_data.shape[0]), :] # Subsample data\n",
    "sinr_data = 10 * np.log10(sinr_data) # Convert to dB\n",
    "#! Warning: converting to dB makes the numbers much closer together, which may make training harder\n",
    "\n",
    "print(\"Shape of the data: \", sinr_data.shape)\n",
    "\n",
    "# Compute statistics\n",
    "mean_sinr_per_sample = np.mean(sinr_data, axis=0)\n",
    "mean_of_means = np.mean(mean_sinr_per_sample)\n",
    "print(f\"Mean of the means of SINR values: {mean_of_means}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of the dataset values\n",
    "fig, axs = plt.subplots(1, 1, sharey=True, tight_layout=True)\n",
    "axs.hist(sinr_data, bins=100, density= True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape: int) -> Model:\n",
    "    \"\"\"\n",
    "    Constructs a neural network model based on the best parameters from Optuna optimization.\n",
    "\n",
    "    Args:\n",
    "        input_shape (int): The number of observed ports (input size).\n",
    "        num_ports (int): Total number of output ports.\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: A compiled Keras Model instance ready for training.\n",
    "    \"\"\"\n",
    "    # ----------------------------- Input Layer ----------------------------- #\n",
    "    inputs = Input(shape=(input_shape,))  # Observed ports as input\n",
    "\n",
    "    # ---------------------------- Dense Layers ---------------------------- #\n",
    "    # First Dense Layer\n",
    "    x = layers.Dense(\n",
    "        units=491,  # Optimized unit count\n",
    "        activation=\"relu\"  # Optimized activation\n",
    "    )(inputs)\n",
    "\n",
    "    # Second Dense Layer\n",
    "    x = layers.Dense(\n",
    "        units=497,  # Optimized unit count\n",
    "        activation=\"relu\"  # Optimized activation\n",
    "    )(x)\n",
    "\n",
    "    # Third Dense Layer\n",
    "    x = layers.Dense(\n",
    "        units=476,  # Optimized unit count\n",
    "        activation=\"tanh\"  # Optimized activation\n",
    "    )(x)\n",
    "\n",
    "    # ------------------------------- Output Layer ------------------------------- #\n",
    "    # Generate the predicted SINR value for each port\n",
    "    outputs = layers.Dense(TOTAL_NUM_PORTS, activation=\"linear\")(x)\n",
    "\n",
    "    return Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Outage Probability Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ideal_op(sinr_data, threshold):\n",
    "    \"\"\"\n",
    "    Computes the outage probability based on the ideal case, which considers the best SINR\n",
    "    value across all ports.\n",
    "\n",
    "    The function finds the maximum SINR value from all available ports for each sample and\n",
    "    checks if it falls below the given threshold. If the maximum SINR for a sample is below\n",
    "    the threshold, the sample is considered to be in outage.\n",
    "\n",
    "    Args:\n",
    "        sinr_data (np.array): SINR data for all ports (shape: num_samples, num_ports).\n",
    "        threshold (float): SINR threshold below which the outage is considered.\n",
    "\n",
    "    Returns:\n",
    "        outage_prob (float): The outage probability based on the ideal case.\n",
    "    \"\"\"\n",
    "    # Maximum SINR across all ports for each sample\n",
    "    max_sinr_all_ports = np.max(sinr_data, axis=1)\n",
    "\n",
    "    # Calculate outage probability: percentage of samples where max SINR is below the threshold\n",
    "    outage_prob = np.mean(max_sinr_all_ports < threshold)\n",
    "\n",
    "    return outage_prob\n",
    "\n",
    "\n",
    "def compute_reference_op(observed_sinr, threshold):\n",
    "    \"\"\"\n",
    "    Computes the outage probability based on the reference case, which considers the best SINR\n",
    "    value from the observed ports.\n",
    "\n",
    "    The function finds the maximum SINR value from the observed ports for each sample and\n",
    "    checks if it falls below the given threshold. If the maximum observed SINR for a sample\n",
    "    is below the threshold, the sample is considered to be in outage.\n",
    "\n",
    "    Args:\n",
    "        observed_sinr (np.array): Observed SINR data for the selected observed ports (shape: num_samples, num_observed_ports).\n",
    "        threshold (float): SINR threshold below which the outage is considered.\n",
    "\n",
    "    Returns:\n",
    "        outage_prob (float): The outage probability based on the reference case.\n",
    "    \"\"\"\n",
    "    # Find the maximum SINR value from the observed ports for each sample\n",
    "    best_observed_sinr = np.max(observed_sinr, axis=1)\n",
    "\n",
    "    # Calculate outage probability: percentage of samples where best observed SINR is below the threshold\n",
    "    outage_prob = np.mean(best_observed_sinr < threshold)\n",
    "\n",
    "    return outage_prob\n",
    "\n",
    "\n",
    "def compute_model_op(predicted_sinr, original_data, threshold):\n",
    "    \"\"\"\n",
    "    Computes the outage probability for the model-generated SINR values by selecting the best-predicted\n",
    "    port for each sample and using the corresponding SINR value from the original SINR data.\n",
    "\n",
    "    Args:\n",
    "        predicted_sinr (np.array): SINR values generated by the model (shape: num_samples, num_ports).\n",
    "        original_data (np.array): Original SINR values for the entire dataset (shape: num_samples, num_ports).\n",
    "        threshold (float): SINR threshold below which the outage is considered.\n",
    "\n",
    "    Returns:\n",
    "        outage_prob (float): The outage probability based on the model-generated SINR values.\n",
    "    \"\"\"\n",
    "    # Step 1: Find the port with the highest predicted SINR value for each sample\n",
    "    best_predicted_ports = np.argmax(predicted_sinr, axis=1)\n",
    "\n",
    "    # Step 2: Retrieve the original SINR values for these best-predicted ports\n",
    "    best_sinr_values = original_data[np.arange(original_data.shape[0]), best_predicted_ports]\n",
    "\n",
    "    # Step 3: Calculate outage probability: percentage of samples where the best SINR is below the threshold\n",
    "    outage_prob = np.mean(best_sinr_values < threshold)\n",
    "\n",
    "    return outage_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_observed_ports(sinr_data, num_obs_ports, num_ports=144):\n",
    "    \"\"\"\n",
    "    Extracts SINR values for the specified number of observed ports.\n",
    "\n",
    "    The function selects a subset of SINR data by identifying equally spaced ports based on the\n",
    "    number of observed ports specified. It returns the SINR values for these observed ports and\n",
    "    their corresponding indices.\n",
    "\n",
    "    Args:\n",
    "        sinr_data (numpy.ndarray): A 2D array where each row represents an observation and each column\n",
    "                                   represents a port with its corresponding SINR values.\n",
    "        num_obs_ports (int): The number of observed ports to select from the SINR data.\n",
    "        num_ports (int, optional): The total number of ports in the SINR data. Defaults to 144.\n",
    "\n",
    "    Returns:\n",
    "        observed_sinr (numpy.ndarray): A 2D array containing the SINR values for the observed ports.\n",
    "        observed_indices (numpy.ndarray): A 1D array of the indices corresponding to the observed ports.\n",
    "    \"\"\"\n",
    "    observed_indices = np.linspace(0, num_ports - 1, num_obs_ports, dtype=int)\n",
    "    observed_sinr = sinr_data[:, observed_indices]\n",
    "\n",
    "    return observed_sinr, observed_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_outage_probability(ideal_data, reference_data, model_data, ports_list):\n",
    "    \"\"\"\n",
    "    Plots the outage probability for ideal, reference, and model-generated data.\n",
    "\n",
    "    The function creates a plot with the number of observed ports on the x-axis and the\n",
    "    outage probability (in logarithmic scale) on the y-axis. It plots the outage probabilities\n",
    "    for the ideal, reference (observed ports), and model-generated data.\n",
    "\n",
    "    Args:\n",
    "        ideal_data (list): Outage probabilities for the ideal SINR data.\n",
    "        reference_data (list): Outage probabilities for the reference (observed ports) SINR data.\n",
    "        model_data (list): Outage probabilities for the model-generated SINR data.\n",
    "        ports_list (list): List of observed port configurations used for the x-axis.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(ports_list, ideal_data, label=\"Ideal\", color=\"blue\", linestyle=\"--\", marker=\"o\")\n",
    "    plt.plot(\n",
    "        ports_list,\n",
    "        reference_data,\n",
    "        label=\"Reference (Observed Ports)\",\n",
    "        color=\"green\",\n",
    "        linestyle=\"-\",\n",
    "        marker=\"x\",\n",
    "    )\n",
    "    plt.ylim(0, 1)\n",
    "    plt.plot(ports_list, model_data, label=\"Model\", color=\"orange\", linestyle=\":\", marker=\"s\")\n",
    "    # plt.yscale(\"log\")  # Logarithmic y-axis\n",
    "    plt.title(\"Outage Probability vs Number of Observed Ports\")\n",
    "    plt.xlabel(\"Number of Observed Ports\")\n",
    "    plt.ylabel(\"Outage Probability\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, which=\"both\", ls=\"--\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_mse(mse_history, title=\"\"):\n",
    "    \"\"\"\n",
    "    Plots the MSE over epochs for a single model trained with a specific number of observed ports.\n",
    "    The y-axis is in logarithmic scale.\n",
    "\n",
    "    Args:\n",
    "        mse_history (list): The MSE history (list of MSE values over epochs) for the model.\n",
    "        observed_ports (int): The number of observed ports used in the model training.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))  # Create a new figure with a specific size\n",
    "\n",
    "    # Plot the MSE history for this model\n",
    "    epochs_range = range(1, len(mse_history) + 1)  # Create an epoch range starting from 1\n",
    "    plt.plot(epochs_range, mse_history, marker=\"o\")\n",
    "\n",
    "    # Set the y-axis to logarithmic scale\n",
    "    # plt.yscale(\"log\")\n",
    "    plt.ylim(0, 1)\n",
    "\n",
    "    # Set the plot title and axis labels\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epoch\")  # X-axis label: epoch number\n",
    "    plt.ylabel(\"Mean Squared Error (MSE)\")  # Y-axis label: MSE value\n",
    "\n",
    "    # Ensure x-axis only shows integers (epochs)\n",
    "    plt.xticks(ticks=epochs_range)  # Set x-axis ticks to the integer values of epochs\n",
    "\n",
    "    # Display the legend\n",
    "    plt.legend()\n",
    "\n",
    "    # Display a grid for better readability\n",
    "    plt.grid(True, which=\"both\", ls=\"--\")  # Grid on both major and minor ticks\n",
    "\n",
    "    # Adjust the layout for better display\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_all_mse_over_epochs(mse_history_list, observed_ports_list, title=\"\"):\n",
    "    \"\"\"\n",
    "    Plots the MSE over epochs for all models trained with different numbers of observed ports on the same plot.\n",
    "    Each model is represented with a different color, and the y-axis is in logarithmic scale.\n",
    "\n",
    "    Args:\n",
    "        mse_history_list (list of lists): A list where each entry is the MSE history (list of MSE values over epochs) for a specific model.\n",
    "        observed_ports_list (list of int): A list of the number of observed ports for each model.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))  # Create a new figure with a specific size\n",
    "\n",
    "    for i, mse_history in enumerate(mse_history_list):\n",
    "        epochs_range = range(1, len(mse_history) + 1)\n",
    "        plt.plot(epochs_range, mse_history, label=f\"{observed_ports_list[i]} observed ports\", marker=\"o\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epoch\")  \n",
    "    plt.ylabel(\"Mean Squared Error (MSE)\")  \n",
    "    plt.xticks(ticks=range(1, max(len(mse_history) for mse_history in mse_history_list) + 1))\n",
    "    plt.ylim(0, 1)\n",
    "\n",
    "    # Move legend outside of the plot\n",
    "    plt.legend(title=\"Observed Ports\", loc=\"center left\", bbox_to_anchor=(1, 0.5))  # Move legend outside\n",
    "    plt.grid(True, which=\"both\", ls=\"--\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Training Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of observed ports up to num_ports with step of 1\n",
    "STEP = 1\n",
    "observed_ports_list = list(range(1, 20 + STEP, STEP))\n",
    "\n",
    "# Prepare the data\n",
    "sinr_train, sinr_test = train_test_split(sinr_data, test_size=0.2, random_state=SEED)\n",
    "SCALER.fit(sinr_data)\n",
    "sinr_train_scaled, sinr_test_scaled = SCALER.transform(sinr_train), SCALER.transform(sinr_test)\n",
    "\n",
    "# Initialize lists to store the results\n",
    "train_mse_history_list = []\n",
    "val_mse_history_list = []\n",
    "outage_prob_ideal_list = []\n",
    "outage_prob_reference_list = []\n",
    "outage_prob_model_list = []\n",
    "best_model_paths = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Training Models for Various Observed Ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in observed_ports_list:\n",
    "    print(f\"Training model with {n} observed ports...\")\n",
    "\n",
    "    # ----------------------------- Data Preparation ----------------------------- #\n",
    "    observed_ports_train, _ = get_observed_ports(sinr_train, n)\n",
    "    observed_ports_test, observed_indices_test = get_observed_ports(sinr_test, n)\n",
    "    \n",
    "    X_train = observed_ports_train\n",
    "    X_test = observed_ports_test\n",
    "    y_train = sinr_train # Real SINR values\n",
    "    y_test = sinr_test # Real SINR values\n",
    "    \n",
    "    # --------------------------------- Callbacks -------------------------------- #\n",
    "    tensorboard_callback = TensorBoard(log_dir=LOG_DIR, histogram_freq=1)\n",
    "    # Run TensorBoard in the terminal using this command: tensorboard --logdir logs/fit\n",
    "    # Run the command at the folder containing the logs directory\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=os.path.join(CHECKPOINT_DIR, f\"best_model_observed_ports_{n}.weights.h5\"),\n",
    "        save_weights_only=True,  # Save only the weights\n",
    "        monitor=\"val_mse\",  # Use validation MSE to monitor the best model\n",
    "        mode=\"min\",\n",
    "        save_best_only=True,  # Save only the best model\n",
    "        verbose=1,  # Verbosity level for saving process\n",
    "    )\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor=\"val_mse\",  # The metric to monitor\n",
    "        mode=\"min\",  # Maximize or minimize the metric\n",
    "        patience=3,  # Number of epochs with no improvement before stopping\n",
    "        verbose=1,  # Verbosity level (0 = silent, 1 = report stopping)\n",
    "        restore_best_weights=True,  # Restore the best weights at the end of training\n",
    "    )\n",
    "\n",
    "    # ------------------------- Build and Train the model ------------------------ #\n",
    "    optimizer = AdamW(learning_rate=8.050158722378705e-05)  # Optimized AdamW settings\n",
    "\n",
    "    model = build_model(n)\n",
    "    model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mse\"])\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[\n",
    "            # early_stopping,\n",
    "            checkpoint_callback,\n",
    "            tensorboard_callback,\n",
    "        ],\n",
    "        verbose=1,\n",
    "    )\n",
    "    \n",
    "    train_mse_history_list.append(history.history[\"loss\"])  # Store loss values\n",
    "    val_mse_history_list.append(history.history[\"val_loss\"])  # Store loss values\n",
    "    plot_mse(history.history[\"loss\"], title=f\"Training loss for model with {n} observed ports\")\n",
    "    plot_mse(history.history[\"val_loss\"], title=f\"Validation loss for model with {n} observed ports\") \n",
    "    \n",
    "    # Store the path of the best model for later loading\n",
    "    best_model_path = os.path.join(CHECKPOINT_DIR, f\"best_model_observed_ports_{n}.weights.h5\")\n",
    "    best_model_paths.append(best_model_path)\n",
    "    \n",
    "    clear_session() # Clear up internal variables of tensorflow, a must for loop training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. Plot MSE over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, n in enumerate(observed_ports_list):\n",
    "    plot_mse(train_mse_history_list[idx], title=f\"Training MSE for model with {n} observed ports\")\n",
    "    plot_mse(val_mse_history_list[idx], title=f\"Validation MSE for model with {n} observed ports\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. Plot the Merged MSE over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a subset of observed ports (e.g., every 5 ports)\n",
    "STEP = 1\n",
    "subset_observed_ports_list = observed_ports_list[::STEP]  # This will select every Xth port\n",
    "\n",
    "# Plot the MSE over epochs for the subset of observed ports\n",
    "subset_mse_history_list = [train_mse_history_list[i] for i in range(0, len(observed_ports_list), STEP)]\n",
    "plot_all_mse_over_epochs(\n",
    "    subset_mse_history_list, subset_observed_ports_list, title=\"Training MSE over Epochs for All Models\"\n",
    ")\n",
    "\n",
    "subset_mse_history_list = [val_mse_history_list[i] for i in range(0, len(observed_ports_list), STEP)]\n",
    "plot_all_mse_over_epochs(\n",
    "    subset_mse_history_list, subset_observed_ports_list, title=\"Validation MSE over Epochs for All Models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3. Load Best Models and Compute Outage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outage_prob_ideal_list = []\n",
    "outage_prob_reference_list = []\n",
    "outage_prob_model_list = []\n",
    "\n",
    "best_model_paths = []\n",
    "for i, n in enumerate(observed_ports_list):\n",
    "    best_model_path = os.path.join(\"weights/dnn\", f\"best_model_observed_ports_{n}.weights.h5\")\n",
    "    best_model_paths.append(best_model_path)\n",
    "\n",
    "sinr_train, sinr_test = train_test_split(sinr_data, test_size=0.2, random_state=SEED)\n",
    "\n",
    "OUTAGE_THRESHOLD = 20\n",
    "\n",
    "# Load Models and Compute Outage\n",
    "for i, n in enumerate(observed_ports_list):\n",
    "    # if i > 40: break\n",
    "    \n",
    "    print(\"Loading: \", best_model_paths[i])\n",
    "    \n",
    "    # ----------------------------- Rebuild the model ---------------------------- #\n",
    "    model = build_model(n)\n",
    "    \n",
    "    # Load the best model saved for the current n configuration\n",
    "    model.load_weights(best_model_paths[i])\n",
    "    \n",
    "    # ------------------------------ Preparing data ------------------------------ #\n",
    "    observed_ports_test, observed_indices_test = get_observed_ports(sinr_test, n)\n",
    "    SCALER.fit(observed_ports_test)\n",
    "    X_test = SCALER.transform(observed_ports_test)\n",
    "    \n",
    "    # ------------------------ Compute Outage Probability ------------------------ #\n",
    "    # Be careful with the number of samples used for the calculation, too little\n",
    "    # and the result will be inaccurate. min = (ideal_op)^-1 * 100\n",
    "\n",
    "    # Compute ideal outage probability (using all ports)\n",
    "    outage_prob_ideal = compute_ideal_op(sinr_test, threshold=OUTAGE_THRESHOLD)\n",
    "    outage_prob_ideal_list.append(outage_prob_ideal)\n",
    "\n",
    "    # Compute reference outage probability (using observed ports)\n",
    "    outage_prob_reference = compute_reference_op(observed_ports_test, threshold=OUTAGE_THRESHOLD)\n",
    "    outage_prob_reference_list.append(outage_prob_reference)\n",
    "    \n",
    "    # Calculate the predicted SINR using the model\n",
    "    predicted_sinr = model.predict(X_test)\n",
    "    \n",
    "    # Compute model outage probability using the predictions\n",
    "    outage_prob_model = compute_model_op(\n",
    "        predicted_sinr, sinr_test, threshold=OUTAGE_THRESHOLD\n",
    "    )\n",
    "    outage_prob_model_list.append(outage_prob_model)\n",
    "\n",
    "# Plot the outage probabilities\n",
    "plot_outage_probability(\n",
    "    outage_prob_ideal_list, outage_prob_reference_list, outage_prob_model_list, observed_ports_list\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
